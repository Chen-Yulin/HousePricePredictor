{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99b021e2",
   "metadata": {},
   "source": [
    "# Homework 6 ‚Äì Models and Pipelines üîÅ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280fb759",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e992c4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hw import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0213e601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80b51b4",
   "metadata": {},
   "source": [
    "## Part 1: `sklearn` Pipelines üß†\n",
    "\n",
    "The file `data/toy.csv` contains an example dataset that consists of 4 columns:\n",
    "\n",
    "- `'group'`: a categorical column with 3 categories\n",
    "- `'c1'`: a numeric attribute\n",
    "- `'c2'`: a numeric attribute\n",
    "- `'y'`: the target variable (that you want to predict) \n",
    "```\n",
    "\n",
    "In the following questions, you will build `Pipeline`s that combine feature engineering with a linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9f1e05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fp = os.path.join('data', 'toy.csv')\n",
    "data = pd.read_csv(fp)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739f0bdb",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "First, you will train a regression model using only a *log-scaled* `'c2'` variable. Create a `Pipeline` that:\n",
    "1. log-scales `'c2'`, then\n",
    "2. predicts `'y'` using a linear regression model (using your transformed `'c2'`).\n",
    "\n",
    "That is, complete the implementation of the function `simple_pipeline`, which takes in a DataFrame like `data` and returns a **tuple** consisting of \n",
    "- An already-fit `Pipeline`, and\n",
    "- An array containing the predictions your model makes on `data` (after being trained on `data`).\n",
    "\n",
    "***Note:*** By \"log\", we're referring to the natural logarithm. In order to log-scale `'c2'`, you'll need to use a `FunctionTransformer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1781f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da1864b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3358c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it \n",
    "q1_fp = os.path.join('data', 'toy.csv')\n",
    "q1_data = pd.read_csv(q1_fp)\n",
    "q1_pl, q1_preds = simple_pipeline(q1_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cabe35aa",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Now, you will engineer features from the other columns and use them to train a regression model.  Create a `Pipeline` that:\n",
    "1. uses `'c1'` as is,\n",
    "1. log-scales `'c2'`,\n",
    "1. one-hot encodes `'group'`, and\n",
    "1. predicts `'y'` using a linear regression model built on the three variables above. (Note that your model will have more than three \"features\", because one-hot encoding `'group'` will create multiple columns. Don't drop any of them.)\n",
    "\n",
    "That is, complete the implementation of the function `multi_type_pipeline`, which takes in a DataFrame like `data` and returns a **tuple** consisting of\n",
    "- An already-fit `Pipeline`, and\n",
    "- An array containing the predictions your model makes on `data` (after being trained on `data`).\n",
    "\n",
    "***Hint:*** Use `ColumnTransformer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9fc7a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b81d20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea08978e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it \n",
    "q2_fp = os.path.join('data', 'toy.csv')\n",
    "q2_data = pd.read_csv(q2_fp)\n",
    "q2_pl, q2_preds = multi_type_pipeline(q2_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab0a6c5",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "It seems like `'c1'` and `'c2'` have strong associations with the values of `'group'` (to see this, run the cell below). This suggests that group-wise scaling might make good features. \n",
    "\n",
    "\n",
    "Now, we want to standardize (i.e. z-score) both `'c1'` and `'c2'` **within each `'group'`** (`'A'`, `'B'`, and `'C'`). Unfortunately, there is no built-in transformer in `sklearn` that performs group-wise standardization, so **you will need to create your own transformer!**\n",
    "\n",
    "Your job is to complete the implementation of the `StdScalerByGroup` transformer class, meaning that you need to implement the `fit` and `transform` methods, along with the constructor (`__init__`).\n",
    "- The `StdScalerByGroup` transformer works on an input array/DataFrame `X` whose first column contains groups, and whose remaining columns are quantitative and need to be standardized (within each group).\n",
    "- The `fit` method should determine the mean and standard deviation of each quantitative column within each group in the input data `X` and save them in the instance variable `grps_`. (For instance, one of the quantities you may calculate here is the standard deviation of `'c1'`, but only for the rows whose `'group'` is `'B'`.)\n",
    "- The `transform` method should take in an input array/DataFrame `X`, standardize each quantitative column separately using the means and standard deviations stored in `grps_`, and return a DataFrame containing the transformed quantitative columns.\n",
    "\n",
    "\n",
    "If you `fit` and `transform` a `StdScalerByGroup` transformer on the `toy` DataFrame (without the `'y'` column), you should get back a DataFrame with two columns, `'c1'` and `'c2'`, with groups stored in the index (if you end up creating a `MultiIndex`, that is fine).\n",
    "\n",
    "\n",
    "***Notes:***\n",
    "1. You may decide on whatever structure you'd like for the `grps_` variable. This question will be graded on the correctness of the output of your transformer. (Check the correctness of your work by checking the output by-hand!)    \n",
    "2. At no point should you loop over the **rows** of `data` (in fact, our solution doesn't use any loops).\n",
    "3. The `'group'` column in the public tests is named `'g'` instead of `'group'`. Remember, the first column will **always** contain the groups, even if the first column's name is something other than `'group'`.\n",
    "4. Do not worry about cases where the standard deviation is equal to 0, the function `std` might work in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a11412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The scatter plot referenced at the start of Question 3\n",
    "# This is not needed to answer the question, but motivates why we are standardizing\n",
    "px.scatter(data, x='c1', y='y', color='group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c9583a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f77636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff110ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it \n",
    "# test fit \n",
    "q3_test_fit_cols = {'g': ['A', 'A', 'B', 'B'], 'c1': [1, 2, 2, 2], 'c2': [3, 1, 2, 0]}\n",
    "q3_test_fit_X = pd.DataFrame(q3_test_fit_cols)\n",
    "q3_test_fit_std = StdScalerByGroup().fit(q3_test_fit_X)\n",
    "\n",
    "# test transform\n",
    "q3_test_transform_cols = {'g': ['A', 'A', 'B', 'B'], 'c1': [1, 2, 3, 4], 'c2': [1, 2, 3, 4]}\n",
    "q3_test_transform_X = pd.DataFrame(q3_test_transform_cols)\n",
    "q3_test_transform_std = StdScalerByGroup().fit(q3_test_transform_X)\n",
    "q3_test_transform_out = q3_test_transform_std.transform(q3_test_transform_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8d799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it \n",
    "q3_fit_data = pd.read_csv('data/toy.csv')\n",
    "\n",
    "N = 2*10**6\n",
    "a = np.random.choice(['A', 'B'], size=(N,1)).astype('object')\n",
    "b = np.random.multivariate_normal([1, 2], [[1, 0],[0, 100]], size=N)\n",
    "arr = np.hstack([a, b])\n",
    "q3_transform_data = pd.DataFrame(arr)\n",
    "q3_transform_data[1] = q3_transform_data[1].astype(float)\n",
    "q3_transform_data[2] = q3_transform_data[2].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fc2d2f",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "`Pipeline`s are supposed to help you easily try different model configurations. Complete the implementation of the function `eval_toy_model`, which returns a hard-coded **list of tuples** consisting of the (RMSE, $R^2$) of three different modeling `Pipeline`s, fit and evaluated on the entire input dataset `data`. The three different `Pipeline`s are:\n",
    "1. The `Pipeline` in Question 1.\n",
    "1. The `Pipeline` in Question 2.\n",
    "1. A `Pipeline` consisting of a linear regression model fit on features generated by applying `StdScalerByGroup` to `'c1'`, log-scaling `'c2'`, and applying `OneHotEncoder` to `'group'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b24c16a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439d918e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7600200",
   "metadata": {},
   "source": [
    "## Congratulations! You've finished homework 6! üéâü•≥\n",
    "\n",
    "As a reminder, all of the work you want to submit needs to be in `hw.py`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de438cb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "otter": {
   "tests": {
    "q1": {
     "name": "q1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(q1_pl, Pipeline)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> isinstance(q1_pl.steps[-1][1], LinearRegression)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> isinstance(q1_pl.steps[0][1], FunctionTransformer)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q1_preds.shape[0] == q1_data.shape[0]\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(q2_pl, Pipeline)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> isinstance(q2_pl.steps[-1][1], LinearRegression)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> isinstance(q2_pl.steps[0][1], ColumnTransformer)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q2_data.shape[0] == q2_preds.shape[0]\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> q3_test_fit_std.grps_ is not None\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q3_test_transform_out.shape == (4, 2)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> np.isclose(q3_test_transform_out.abs(), 0.707107, atol=0.001).all().all()\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> out = eval_toy_model()\n>>> len(out) == 3\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> out = eval_toy_model()\n>>> np.all([len(t) == 2 for t in out])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> (out_tree_test.columns.tolist() == ['train_err', 'test_err']) == True\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> (out_tree_test['train_err'].iloc[-1] < out_tree_test['test_err'].iloc[-1]) == True\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> (out_knn_test.columns.tolist() == ['train_err', 'test_err']) == True\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6": {
     "name": "q6",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(pl_test, Pipeline)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> isinstance(pl_test.steps[-1][-1], BaseEstimator)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> preds_test = pl_test.predict(q6_data_test.drop('Survived', axis=1))\n>>> ((preds_test == 0) | (preds_test == 1)).all()\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "fa21447ba3ca0ac29cfe033d1e623e3db9da50a3031a1ad33c9e1c367d9ba6e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
